# -*- coding: utf-8 -*-
"""video_gen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hGgIXgCW84oQlgxk7L5SVHNQmKWOIqKP
"""

!pip install addict
!pip install -q transformers accelerate diffusers einops imageio moviepy

import torch
from diffusers import DiffusionPipeline
import imageio
import numpy as np
import os
from moviepy.editor import ImageSequenceClip
from PIL import Image

from moviepy.editor import VideoFileClip, concatenate_videoclips

# !rm -rf video_frames/

pipe = DiffusionPipeline.from_pretrained(
    "damo-vilab/text-to-video-ms-1.7b",
    torch_dtype=torch.float16,
    variant="fp16"
).to("cuda")

def make_video(frames1):

  os.makedirs("video_frames", exist_ok=True)


  for i, frame in enumerate(frames1):
        if frame.dtype != np.uint8:
            frame = (np.clip(frame, 0, 1) * 255).astype(np.uint8)
        Image.fromarray(frame).save(f"video_frames/frame_{i:03d}.png")
        print(f"Saved frame {i}: shape={frame.shape}, dtype={frame.dtype}")


  frame_paths = sorted([f"video_frames/{f}" for f in os.listdir("video_frames") if f.endswith(".png")])
  clip = ImageSequenceClip(frame_paths, fps=8)

  looped_clip=concatenate_videoclips([clip,clip])
  looped_clip.write_videofile("/content/output.mp4", codec="libx264")

import os
import numpy as np
from PIL import Image

def generate(input):

  prompt = input
  output = pipe(prompt, num_inference_steps=25, num_frames=32, height=256, width=256)
  frames = output.frames


  frames1 = frames[0]
  make_video(frames1)

!pip install fastapi uvicorn python-multipart pyngrok

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.responses import FileResponse
from pyngrok import ngrok
import shutil
import requests
import os

app = FastAPI()

from fastapi import HTTPException

@app.post("/generate/")
async def process_url(prompt: str = Form(...)):
    try:
        print(" Received prompt:", prompt)
        print(" Running pipeline...")
        generate(prompt)
        output_path = "/content/output.mp4"
        print("Pipeline completed.")

        if not os.path.exists(output_path):
            raise HTTPException(status_code=500, detail="Output video not found.")

        print(" Sending back file:", output_path)
        return FileResponse(output_path, media_type="video/mp4")

    except Exception as e:
        print(" ERROR:", str(e))
        raise HTTPException(status_code=500, detail=f"Processing failed: {str(e)}")

!ngrok config add-authtoken YOUR_AUTH_TOKEN

import threading
import uvicorn


# Start FastAPI server in background
def run():
    uvicorn.run(app, host="0.0.0.0", port=8000)

thread = threading.Thread(target=run)
thread.start()

#  Start ngrok tunnel
public_url = ngrok.connect(8000)
print(" Public URL:", public_url)

torch.cuda.empty_cache()

# !curl -X POST https://25611378bd97.ngrok-free.app/generate/ \
#    -F "prompt=a cute cat dancing" \
#    --output final_output.mp4

# from IPython.display import HTML
# from base64 import b64encode

# # Function to display a video in the notebook
# def display_video(filename):
#     mp4 = open(filename, 'rb').read()
#     data_url = "data:video/mp4;base64," + b64encode(mp4).decode()
#     return HTML(f"""
#       <video width=640 controls autoplay loop>
#             <source src="{data_url}" type="video/mp4">
#       </video>
#       """)

# # Display the new video
# display_video("output.mp4")