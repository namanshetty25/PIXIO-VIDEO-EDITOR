{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishabh-2005/IITISoC-ML-05/blob/main/features/object_inpainting/User_click.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "r3LDmykSBsRZ"
      },
      "outputs": [],
      "source": [
        "!pip install -q ultralytics opencv-python-headless diffusers torch torchvision ffmpeg-python fastapi uvicorn python-multipart pyngrok supervision\n",
        "!git clone https://github.com/sczhou/ProPainter.git\n",
        "%cd ProPainter\n",
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2, numpy as np, os, subprocess, shutil\n",
        "\n",
        "def get_track_id_at_frame(model, video_path, click_x, click_y, frame_number):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    target_id = None\n",
        "    for i in range(frame_number + 1):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        if i == frame_number:\n",
        "            result = model.track(frame, persist=True)[0]\n",
        "            boxes, ids = result.boxes.xyxy, result.boxes.id\n",
        "            for j, box in enumerate(boxes):\n",
        "                x1, y1, x2, y2 = map(int, box.tolist())\n",
        "                if x1 <= click_x <= x2 and y1 <= click_y <= y2:\n",
        "                    target_id = int(ids[j])\n",
        "                    break\n",
        "    cap.release()\n",
        "    return target_id\n",
        "\n",
        "def generate_mask_for_id(model, video_path, target_id, mask_folder):\n",
        "    os.makedirs(mask_folder, exist_ok=True)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    idx = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        result = model.track(frame, persist=True)[0]\n",
        "        masks = result.masks.data if result.masks else []\n",
        "        ids = result.boxes.id if result.boxes.id is not None else []\n",
        "        mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)\n",
        "        for i, seg_mask in enumerate(masks):\n",
        "            if int(ids[i]) == target_id:\n",
        "                m = seg_mask.cpu().numpy().astype(np.uint8)\n",
        "                m = cv2.resize(m, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "                mask = m * 255\n",
        "                break\n",
        "        cv2.imwrite(f\"{mask_folder}/frame_{idx:04d}.png\", mask)\n",
        "        idx += 1\n",
        "    cap.release()\n",
        "\n",
        "def run_pipeline(input_path, x, y, frame, output_path=\"/content/outputs/final_output_with_audio.mp4\"):\n",
        "    model = YOLO(\"yolov8x-seg.pt\")\n",
        "    mask_folder = \"/content/yolo_seg_masks_object\"\n",
        "    shutil.rmtree(mask_folder, ignore_errors=True)\n",
        "\n",
        "\n",
        "    target_id = get_track_id_at_frame(model, input_path, x, y, frame)\n",
        "    if target_id is None:\n",
        "        raise Exception(\"Target object not found at given coordinate/frame\")\n",
        "\n",
        "\n",
        "    generate_mask_for_id(model, input_path, target_id, mask_folder)\n",
        "\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    w, h = int(cap.get(3)), int(cap.get(4))\n",
        "    cap.release()\n",
        "\n",
        "    !python /content/ProPainter/inference_propainter.py \\\n",
        "        --video {input_path} \\\n",
        "        --mask {mask_folder} \\\n",
        "        --output /content/outputs \\\n",
        "        --width 640 --height 360 \\\n",
        "        --subvideo_length 10\n",
        "\n",
        "    %cd /content\n",
        "\n",
        "    inpainted_path = \"/content/outputs/input/inpaint_out.mp4\"\n",
        "    audio_path = \"/content/original_audio.aac\"\n",
        "\n",
        "\n",
        "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", input_path, \"-vn\", \"-acodec\", \"copy\", audio_path], check=True)\n",
        "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", inpainted_path, \"-i\", audio_path,\n",
        "                    \"-c:v\", \"copy\", \"-c:a\", \"aac\", \"-strict\", \"experimental\", output_path], check=True)\n",
        "    return output_path"
      ],
      "metadata": {
        "id": "vtE7q-k1BzOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, UploadFile, File, Form, HTTPException\n",
        "from fastapi.responses import FileResponse\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import uvicorn\n",
        "import requests\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/remove/\")\n",
        "async def remove_object(\n",
        "    video_url: str = Form(...),\n",
        "    x: int = Form(...),\n",
        "    y: int = Form(...),\n",
        "    frame: int = Form(...)\n",
        "):\n",
        "\n",
        "    try:\n",
        "\n",
        "        input_path = \"/content/input.mp4\"\n",
        "        response = requests.get(video_url, stream=True)\n",
        "        if response.status_code != 200:\n",
        "            raise HTTPException(status_code=400, detail=\"Video download failed.\")\n",
        "\n",
        "        with open(input_path, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "\n",
        "        output_path = run_pipeline(input_path, x, y, frame)\n",
        "\n",
        "\n",
        "        return FileResponse(output_path, media_type=\"video/mp4\", filename=\"inpainted_with_audio.mp4\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\" ERROR:\", str(e))\n",
        "        raise HTTPException(status_code=500, detail=f\"Processing failed: {str(e)}\")"
      ],
      "metadata": {
        "id": "ynEv8Z9XDrM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken YOUR_AUTH_TOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wguvrAxoD0v3",
        "outputId": "90579411-1f67-46fc-a94f-42a3e9c86d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def run():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=3000)\n",
        "\n",
        "thread = threading.Thread(target=run)\n",
        "thread.start()\n",
        "\n",
        "public_url = ngrok.connect(3000)\n",
        "print(\"Public URL:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbhaC0k3Dti5",
        "outputId": "e529bea9-8091-44c4-f805-ea537f9fad75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [816]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "ERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 3000): address already in use\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Public URL: NgrokTunnel: \"https://16550d4c6910.ngrok-free.app\" -> \"http://localhost:3000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/input.mp4"
      ],
      "metadata": {
        "id": "4AxVab3AHCbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !curl -X POST https://16550d4c6910.ngrok-free.app/remove/ \\\n",
        "#   -F \"video_url=https://res.cloudinary.com/dvdykz9el/video/upload/v1750874160/butterfly_ku8qyt.mp4\" \\\n",
        "#   -F \"x=984\" \\\n",
        "#   -F \"y=523\" \\\n",
        "#   -F \"frame=0\" \\\n",
        "#   --output inpainted_with_audio.mp4"
      ],
      "metadata": {
        "id": "IKYllQgoEV_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R /content/outputs/input/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x-c1WAyH8np",
        "outputId": "254cd866-9efa-4cbf-fbc0-80746cfe6353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/outputs/input/:\n"
          ]
        }
      ]
    }
  ]
}