{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishabh-2005/IITISoC-ML-05/blob/main/features/object_inpainting/Auto_detect\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "z2bMkBe76Dcj"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics opencv-python-headless diffusers torch torchvision ffmpeg-python\n",
        "!git clone https://github.com/sczhou/ProPainter.git\n",
        "%cd ProPainter\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess"
      ],
      "metadata": {
        "id": "lQhp4nWZl0cL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def has_audio_stream(video_path):\n",
        "\n",
        "    result = subprocess.run(\n",
        "        [\"ffprobe\", \"-i\", video_path, \"-show_streams\", \"-select_streams\", \"a\", \"-loglevel\", \"error\"],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "    )\n",
        "    return result.stdout != b\"\""
      ],
      "metadata": {
        "id": "M5SZdqUHgwJn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(input_path, output_path=\"/content/outputs/final.mp4\"):\n",
        "    from ultralytics import YOLO\n",
        "    import cv2\n",
        "    import os\n",
        "    import numpy as np\n",
        "    import shutil\n",
        "    import subprocess\n",
        "\n",
        "    def generate_mask(frame, results):\n",
        "        mask = np.zeros_like(frame[:, :, 0], dtype=np.uint8)\n",
        "        for result in results:\n",
        "            if result.masks is not None:\n",
        "                for seg_mask in result.masks.data:\n",
        "                    seg_mask_np = seg_mask.cpu().numpy().astype(np.uint8)\n",
        "                    seg_mask_resized = cv2.resize(seg_mask_np, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "                    mask = cv2.bitwise_or(mask, seg_mask_resized * 255)\n",
        "                    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
        "                    mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "                    mask = cv2.GaussianBlur(mask, (5,5), 0)\n",
        "        return mask\n",
        "\n",
        "    # Load YOLO model\n",
        "    model = YOLO(\"yolov8x-seg.pt\")\n",
        "\n",
        "    # Prepare folders\n",
        "    mask_folder = \"/content/yolo_seg_masks\"\n",
        "    os.makedirs(mask_folder, exist_ok=True)\n",
        "\n",
        "    # Read video and create masks\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    frame_idx = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        results = model(frame)\n",
        "        mask = generate_mask(frame, results)\n",
        "        mask_path = os.path.join(mask_folder, f\"frame_{frame_idx:04d}.png\")\n",
        "        cv2.imwrite(mask_path, mask)\n",
        "        frame_idx += 1\n",
        "    cap.release()\n",
        "\n",
        "    import os\n",
        "\n",
        "    if not os.path.exists(\"/content/ProPainter\"):\n",
        "      !git clone https://github.com/sczhou/ProPainter.git\n",
        "    %cd /content/ProPainter\n",
        "    !pip install -r requirements.txt\n",
        "\n",
        "\n",
        "    # Run ProPainter\n",
        "    !python /content/ProPainter/inference_propainter.py \\\n",
        "        --video {input_path} \\\n",
        "        --mask {mask_folder} \\\n",
        "        --output /content/outputs \\\n",
        "        --width 480 --height 270 \\\n",
        "        --subvideo_length 10\n",
        "\n",
        "    %cd /content\n",
        "\n",
        "\n",
        "    # Output path from ProPainter\n",
        "    inpainted_path = \"/content/outputs/input/inpaint_out.mp4\"\n",
        "    audio_path = \"/content/original_audio.aac\"\n",
        "    output_path = \"/content/outputs/final.mp4\"\n",
        "\n",
        "\n",
        "\n",
        "    if has_audio_stream(input_path):\n",
        "\n",
        "        subprocess.run([\"ffmpeg\", \"-y\", \"-i\", input_path, \"-vn\", \"-acodec\", \"copy\", audio_path], check=True)\n",
        "        subprocess.run([\n",
        "            \"ffmpeg\", \"-y\", \"-i\", inpainted_path, \"-i\", audio_path,\n",
        "            \"-c:v\", \"copy\", \"-c:a\", \"aac\", \"-strict\", \"experimental\", output_path\n",
        "        ], check=True)\n",
        "    else:\n",
        "\n",
        "        shutil.copy(inpainted_path, output_path)\n",
        "\n",
        "    shutil.rmtree(mask_folder, ignore_errors=True)\n",
        "    return output_path"
      ],
      "metadata": {
        "id": "MJ5OXdtUQfeO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn python-multipart pyngrok\n",
        "\n",
        "from fastapi import FastAPI, UploadFile, File, Form\n",
        "from fastapi.responses import FileResponse\n",
        "from pyngrok import ngrok\n",
        "import shutil\n",
        "import requests\n",
        "import os\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "from fastapi import HTTPException\n",
        "\n",
        "@app.post(\"/process/\")\n",
        "async def process_url(video_url: str = Form(...)):\n",
        "    try:\n",
        "        print(\" Received URL:\", video_url)\n",
        "\n",
        "        input_path = \"/content/input.mp4\"\n",
        "        output_path = \"/content/outputs/final.mp4\"\n",
        "\n",
        "        print(\" Downloading video...\")\n",
        "        response = requests.get(video_url, stream=True)\n",
        "        if response.status_code != 200:\n",
        "            raise HTTPException(status_code=400, detail=\"Video download failed.\")\n",
        "\n",
        "        with open(input_path, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        print(\" Video saved.\")\n",
        "\n",
        "        print(\" Running pipeline...\")\n",
        "        run_pipeline(input_path)\n",
        "        print(\"Pipeline completed.\")\n",
        "\n",
        "        if not os.path.exists(output_path):\n",
        "            raise HTTPException(status_code=500, detail=\"Output video not found.\")\n",
        "\n",
        "        print(\" Sending back file:\", output_path)\n",
        "        return FileResponse(output_path, media_type=\"video/mp4\", filename=\"inpainted_video.mp4\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\" ERROR:\", str(e))\n",
        "        raise HTTPException(status_code=500, detail=f\"Processing failed: {str(e)}\")"
      ],
      "metadata": {
        "id": "8LSqTbauQj3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken YOUR_AUTH_TOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpXrOc1ZHRfO",
        "outputId": "e7850c06-6e44-4efb-bc00-a3bf3944159f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Start FastAPI server in background\n",
        "def run():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "thread = threading.Thread(target=run)\n",
        "thread.start()\n",
        "\n",
        "#  Start ngrok tunnel\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\" Public URL:\", public_url)"
      ],
      "metadata": {
        "id": "iY5AkpT9UHiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d626e965-0e12-4580-a1fb-c628f077ca08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [892]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Public URL: NgrokTunnel: \"https://3ed499eb22e3.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        }
      ]
    }
  ]
}