{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDCg1L-W9bTI",
        "outputId": "4fec3793-180c-4414-a6ab-bb6b451933ff"
      },
      "outputs": [],
      "source": [
        "pip install opencv-python scikit-image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AsJ6KAR-D-G",
        "outputId": "0705d9e7-0d5a-4925-9d11-d80e003e3bab"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Paths to input and output videos\n",
        "input_video_path = '/content/input.mp4'\n",
        "output_video_path = '/content/REALESR output.mp4'\n",
        "\n",
        "# Open the video files\n",
        "input_cap = cv2.VideoCapture(input_video_path)\n",
        "output_cap = cv2.VideoCapture(output_video_path)\n",
        "\n",
        "# Check if videos opened successfully\n",
        "if not input_cap.isOpened():\n",
        "    print(f\"Error: Could not open input video: {input_video_path}\")\n",
        "if not output_cap.isOpened():\n",
        "    print(f\"Error: Could not open output video: {output_video_path}\")\n",
        "\n",
        "if input_cap.isOpened() and output_cap.isOpened():\n",
        "    # Check total frames (optional validation)\n",
        "    frame_count = int(min(input_cap.get(cv2.CAP_PROP_FRAME_COUNT), output_cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "    print(f\"Processing {frame_count} frames...\")\n",
        "\n",
        "    total_psnr = 0\n",
        "    total_ssim = 0\n",
        "\n",
        "    for i in range(frame_count):\n",
        "        ret1, frame1 = input_cap.read()\n",
        "        ret2, frame2 = output_cap.read()\n",
        "\n",
        "        if not ret1 or not ret2:\n",
        "            print(f\"Frame read failed at index {i}\")\n",
        "            break\n",
        "\n",
        "        # Convert to grayscale for SSIM (optional: if you want per-channel SSIM, use color)\n",
        "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
        "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Resize input to output resolution if needed\n",
        "        if gray1.shape != gray2.shape:\n",
        "            gray1 = cv2.resize(gray1, (gray2.shape[1], gray2.shape[0]))\n",
        "            frame1 = cv2.resize(frame1, (frame2.shape[1], frame2.shape[0]))\n",
        "\n",
        "        total_psnr += psnr(frame2, frame1, data_range=255)\n",
        "        total_ssim += ssim(gray2, gray1, data_range=255)\n",
        "\n",
        "    # Average metrics\n",
        "    if frame_count > 0:\n",
        "        avg_psnr = total_psnr / frame_count\n",
        "        avg_ssim = total_ssim / frame_count\n",
        "        print(f\"\\nAverage PSNR: {avg_psnr:.2f} dB\")\n",
        "        print(f\"Average SSIM: {avg_ssim:.4f}\")\n",
        "    else:\n",
        "        print(\"No frames were processed.\")\n",
        "\n",
        "# Release resources\n",
        "input_cap.release()\n",
        "output_cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tLtgtllNfev"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
